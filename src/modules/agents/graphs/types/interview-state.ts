/**
 * Interview State
 *
 * State schema for the Interview Agent graph.
 * Defines all state fields needed for multi-turn
 * intent extraction conversations.
 */

import { Annotation } from '@langchain/langgraph';

// ============================================================================
// Types
// ============================================================================

/**
 * Phases of the interview graph.
 */
export type InterviewPhase =
  | 'analyze'
  | 'generate_questions'
  | 'waiting_for_response'
  | 'extract_atoms'
  | 'compose_molecule'
  | 'complete';

/**
 * Rich answer classification for interview questions.
 * More expressive than a boolean `answered` flag.
 */
export type AnswerStatus =
  | 'answered' // User provided a substantive answer
  | 'deferred' // User explicitly postponed ("later", "not now", "Phase 2")
  | 'unanswered' // No relevant information provided for this question
  | 'out_of_scope' // User declared this topic out of current scope
  | 'conflict'; // Answer contradicts earlier information

/**
 * How a response was scoped relative to questions.
 * - 'individual': response maps to a specific question (production mode)
 * - 'batch': single response applied to all questions in a round (fixture mode)
 */
export type ResponseScope = 'individual' | 'batch';

/**
 * Why the interview completed.
 */
export type CompletionReason =
  | 'user_signaled_done' // User explicitly said they're done
  | 'max_rounds_reached' // Hit the maximum round limit
  | 'no_more_questions' // LLM determined no useful questions remain
  | 'simulation_exhausted' // Fixture mode ran out of simulated responses
  | 'error'; // An error forced early termination

/**
 * A question generated by the interview agent.
 */
export interface InterviewQuestion {
  /** Unique ID for tracking */
  id: string;
  /** The question text */
  question: string;
  /** Why this question matters */
  rationale: string;
  /** Category of clarification needed */
  category: 'scope' | 'behavior' | 'constraint' | 'acceptance' | 'edge_case';
  /** Whether this question has been answered (backward-compat boolean) */
  answered: boolean;
  /** Rich answer classification */
  answerStatus?: AnswerStatus;
  /** How the response was scoped (individual per-question vs batch for round) */
  responseScope?: ResponseScope;
  /** The user's response */
  response?: string;
}

/**
 * An atom candidate extracted from the conversation.
 */
export interface AtomCandidate {
  /** Proposed description */
  description: string;
  /** Atom category */
  category: 'functional' | 'performance' | 'security' | 'ux' | 'operational';
  /** Observable outcomes */
  observableOutcomes: string[];
  /** Confidence in this extraction (0-100) */
  confidence: number;
  /** Which parts of the conversation support this atom */
  sourceEvidence: string[];
}

/**
 * A molecule candidate composed from extracted atoms.
 */
export interface MoleculeCandidate {
  /** Proposed molecule name */
  name: string;
  /** Description */
  description: string;
  /** Suggested lens type */
  lensType: string;
  /** Indices into the atoms array */
  atomIndices: number[];
}

/**
 * A single turn in the interview conversation.
 */
export interface ConversationTurn {
  role: 'user' | 'assistant';
  content: string;
  timestamp: string;
}

/**
 * A simulated user response for fixture/golden test mode.
 * These are provided upfront to run the interview without human interaction.
 */
export interface SimulatedResponse {
  /** The simulated user response content */
  content: string;
  /** Whether this response signals the user is done */
  signalsDone?: boolean;
}

// ============================================================================
// State Schema
// ============================================================================

/**
 * Interview graph state using LangGraph Annotation.
 */
export const InterviewGraphState = Annotation.Root({
  /** Original user input that started the interview */
  rawIntent: Annotation<string>(),

  /** Current phase of the interview */
  currentPhase: Annotation<InterviewPhase>({
    reducer: (_prev, next) => next,
    default: () => 'analyze',
  }),

  /** Conversation history */
  conversationHistory: Annotation<ConversationTurn[]>({
    reducer: (prev, next) => [...prev, ...next],
    default: () => [],
  }),

  /** Analysis of the initial intent */
  intentAnalysis: Annotation<{
    summary: string;
    ambiguities: string[];
    impliedBehaviors: string[];
    suggestedCategory: string;
  } | null>({
    reducer: (_prev, next) => next,
    default: () => null,
  }),

  /** Questions to ask the user */
  pendingQuestions: Annotation<InterviewQuestion[]>({
    reducer: (_prev, next) => next,
    default: () => [],
  }),

  /** All questions asked across all rounds */
  allQuestions: Annotation<InterviewQuestion[]>({
    reducer: (prev, next) => [...prev, ...next],
    default: () => [],
  }),

  /** Extracted atom candidates */
  atomCandidates: Annotation<AtomCandidate[]>({
    reducer: (_prev, next) => next,
    default: () => [],
  }),

  /** Composed molecule candidates */
  moleculeCandidates: Annotation<MoleculeCandidate[]>({
    reducer: (_prev, next) => next,
    default: () => [],
  }),

  /** Current interview round (1-based) */
  round: Annotation<number>({
    reducer: (_prev, next) => next,
    default: () => 1,
  }),

  /** Maximum rounds before auto-extracting */
  maxRounds: Annotation<number>({
    reducer: (_prev, next) => next,
    default: () => 5,
  }),

  /** Whether the user signaled they're done answering */
  userDone: Annotation<boolean>({
    reducer: (_prev, next) => next,
    default: () => false,
  }),

  /** Why the interview completed */
  completionReason: Annotation<CompletionReason | null>({
    reducer: (_prev, next) => next,
    default: () => null,
  }),

  /** Errors encountered */
  errors: Annotation<string[]>({
    reducer: (prev, next) => [...prev, ...next],
    default: () => [],
  }),

  /** Final output message for the user */
  output: Annotation<string>({
    reducer: (_prev, next) => next,
    default: () => '',
  }),

  /** LLM call count for cost tracking */
  llmCallCount: Annotation<number>({
    reducer: (_prev, next) => next,
    default: () => 0,
  }),

  // =========================================================================
  // Fixture Mode (Golden Test Evaluation)
  // =========================================================================

  /**
   * Simulated user responses for fixture/golden test mode.
   * When provided, the graph uses these instead of interrupting for real user input.
   */
  simulatedResponses: Annotation<SimulatedResponse[]>({
    reducer: (_prev, next) => next,
    default: () => [],
  }),

  /**
   * Index tracking which simulated response to use next.
   */
  simulatedResponseIndex: Annotation<number>({
    reducer: (_prev, next) => next,
    default: () => 0,
  }),

  /**
   * Context provided by the scenario (domain, constraints, etc.)
   */
  scenarioContext: Annotation<{
    domain?: string;
    constraints?: string[];
    persona?: string;
    invariants?: string[];
  } | null>({
    reducer: (_prev, next) => next,
    default: () => null,
  }),
});

/**
 * Type alias for the interview graph state
 */
export type InterviewGraphStateType = typeof InterviewGraphState.State;
